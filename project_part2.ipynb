{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "project_part2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Galzi1/DataDiscoveryNNProj/blob/master/project_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDzKT-jJCqlb",
        "colab_type": "text"
      },
      "source": [
        "# Knowledge Data Discovery and Neural Networks : Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RNH1oP_Cqlc",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we will prepare data and run several algorithms for classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT8nIf--Cqlc",
        "colab_type": "text"
      },
      "source": [
        "# 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POfS3zjTCqld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add more packages in this section\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dredJsfHCqlg",
        "colab_type": "text"
      },
      "source": [
        "# 2. data preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JKEhltnCqlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data = pd.read_csv(\"data/adult.data\", header = None)\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/Galzi1/DataDiscoveryNNProj/master/data/adult.data\", header = None)\n",
        "cols = ['age', 'workclass', 'fnlwgt','education','education_num','marital_status','occupation','relationship','race','sex','capital_gain', 'capital_loss'\n",
        "    ,'hours_per_week','native_country','y']\n",
        "data.columns = cols"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARDQJAR7Cqlj",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Categorical feature handling\n",
        "* Name two machine learning algorithms that can deal with categorical features without special handling?\n",
        "\n",
        "special handling = one hot encoding exc.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suReLsHsCqlj",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "* Naive Bayes (explain some)\n",
        "* Some Tree-based algorithm (specify one and explain)\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0uySf-WCqlk",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 One hot encoding \n",
        "\n",
        "* Remove the y column from the data variable and save it to the variable y\n",
        "* Transform the categorical columns to one hot encoding\n",
        "\n",
        "You may find get_dummies function in pandas useful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMmmDqo-Cqlk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "6acb6c9a-5381-4fdc-f27f-75f0b6413787"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "y = data['y']\n",
        "X = data.drop(['y'], axis=1)\n",
        "\n",
        "obj_cols = list(X.select_dtypes(include=['object']).columns)\n",
        "\n",
        "X = pd.get_dummies(X, columns=obj_cols, drop_first=True)\n",
        "\n",
        "X.head()\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education_num</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>workclass_ Federal-gov</th>\n",
              "      <th>workclass_ Local-gov</th>\n",
              "      <th>workclass_ Never-worked</th>\n",
              "      <th>workclass_ Private</th>\n",
              "      <th>workclass_ Self-emp-inc</th>\n",
              "      <th>workclass_ Self-emp-not-inc</th>\n",
              "      <th>workclass_ State-gov</th>\n",
              "      <th>workclass_ Without-pay</th>\n",
              "      <th>education_ 11th</th>\n",
              "      <th>education_ 12th</th>\n",
              "      <th>education_ 1st-4th</th>\n",
              "      <th>education_ 5th-6th</th>\n",
              "      <th>education_ 7th-8th</th>\n",
              "      <th>education_ 9th</th>\n",
              "      <th>education_ Assoc-acdm</th>\n",
              "      <th>education_ Assoc-voc</th>\n",
              "      <th>education_ Bachelors</th>\n",
              "      <th>education_ Doctorate</th>\n",
              "      <th>education_ HS-grad</th>\n",
              "      <th>education_ Masters</th>\n",
              "      <th>education_ Preschool</th>\n",
              "      <th>education_ Prof-school</th>\n",
              "      <th>education_ Some-college</th>\n",
              "      <th>marital_status_ Married-AF-spouse</th>\n",
              "      <th>marital_status_ Married-civ-spouse</th>\n",
              "      <th>marital_status_ Married-spouse-absent</th>\n",
              "      <th>marital_status_ Never-married</th>\n",
              "      <th>marital_status_ Separated</th>\n",
              "      <th>marital_status_ Widowed</th>\n",
              "      <th>occupation_ Adm-clerical</th>\n",
              "      <th>occupation_ Armed-Forces</th>\n",
              "      <th>occupation_ Craft-repair</th>\n",
              "      <th>occupation_ Exec-managerial</th>\n",
              "      <th>occupation_ Farming-fishing</th>\n",
              "      <th>...</th>\n",
              "      <th>native_country_ Canada</th>\n",
              "      <th>native_country_ China</th>\n",
              "      <th>native_country_ Columbia</th>\n",
              "      <th>native_country_ Cuba</th>\n",
              "      <th>native_country_ Dominican-Republic</th>\n",
              "      <th>native_country_ Ecuador</th>\n",
              "      <th>native_country_ El-Salvador</th>\n",
              "      <th>native_country_ England</th>\n",
              "      <th>native_country_ France</th>\n",
              "      <th>native_country_ Germany</th>\n",
              "      <th>native_country_ Greece</th>\n",
              "      <th>native_country_ Guatemala</th>\n",
              "      <th>native_country_ Haiti</th>\n",
              "      <th>native_country_ Holand-Netherlands</th>\n",
              "      <th>native_country_ Honduras</th>\n",
              "      <th>native_country_ Hong</th>\n",
              "      <th>native_country_ Hungary</th>\n",
              "      <th>native_country_ India</th>\n",
              "      <th>native_country_ Iran</th>\n",
              "      <th>native_country_ Ireland</th>\n",
              "      <th>native_country_ Italy</th>\n",
              "      <th>native_country_ Jamaica</th>\n",
              "      <th>native_country_ Japan</th>\n",
              "      <th>native_country_ Laos</th>\n",
              "      <th>native_country_ Mexico</th>\n",
              "      <th>native_country_ Nicaragua</th>\n",
              "      <th>native_country_ Outlying-US(Guam-USVI-etc)</th>\n",
              "      <th>native_country_ Peru</th>\n",
              "      <th>native_country_ Philippines</th>\n",
              "      <th>native_country_ Poland</th>\n",
              "      <th>native_country_ Portugal</th>\n",
              "      <th>native_country_ Puerto-Rico</th>\n",
              "      <th>native_country_ Scotland</th>\n",
              "      <th>native_country_ South</th>\n",
              "      <th>native_country_ Taiwan</th>\n",
              "      <th>native_country_ Thailand</th>\n",
              "      <th>native_country_ Trinadad&amp;Tobago</th>\n",
              "      <th>native_country_ United-States</th>\n",
              "      <th>native_country_ Vietnam</th>\n",
              "      <th>native_country_ Yugoslavia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>77516</td>\n",
              "      <td>13</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>83311</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>215646</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>234721</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>338409</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  fnlwgt  ...  native_country_ Vietnam  native_country_ Yugoslavia\n",
              "0   39   77516  ...                        0                           0\n",
              "1   50   83311  ...                        0                           0\n",
              "2   38  215646  ...                        0                           0\n",
              "3   53  234721  ...                        0                           0\n",
              "4   28  338409  ...                        0                           0\n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bh315H_Cqlm",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Train test split\n",
        "\n",
        "* Convert the y column - replace <=50K with 0 and >50K with 1 \n",
        "* Split the dataset into train and test set (use 15% for the test set)\n",
        "\n",
        "at the end, make sure you have the following variables:\n",
        "\n",
        "* X\n",
        "* y\n",
        "* X_train\n",
        "* X_test\n",
        "* y_train\n",
        "* y_test\n",
        "\n",
        "You may find sklearn train_test_split useful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8x0S20LCqln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "Y = labelencoder.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRA1aiKyCqlo",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Numeric feature normalization\n",
        "\n",
        "* Scale the numeric features to to have zero mean (z score normalization)\n",
        "\n",
        "- Don't scale the boolean features\n",
        "\n",
        "You may find sklearn StandardScaler useful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC62JGeECqlp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "6c70d8e8-35c1-41db-a43a-7fa56613ed46"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "def standardize_column(col):\n",
        "    name = col.name\n",
        "    x = col.values\n",
        "    x = x.reshape(-1, 1)\n",
        "    scaler = preprocessing.StandardScaler()\n",
        "    x_scaled = scaler.fit_transform(x)\n",
        "    srs_standardized = pd.Series(x_scaled.flatten())\n",
        "    srs_standardized.name = name\n",
        "    return srs_standardized\n",
        "\n",
        "\n",
        "for c in X_train.columns:\n",
        "  if X_train[c].dtype == np.int64:\n",
        "    X_train[c] = standardize_column(X_train[c])\n",
        "    \n",
        "### END YOUR CODE"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoJomS7QCqlr",
        "colab_type": "text"
      },
      "source": [
        "# 3 Models\n",
        "\n",
        "Create a function `cv(x, y, model)` (cv stands for cross validation) that gets a model (sklearn classifier) and the data.  \n",
        "The function should fit the model using k fold cross validation with k = 5, and print the 'roc_auc' on each fold (which is the scoring parameter for the cross val_score function).\n",
        "\n",
        "\n",
        "[Computing cross-validated metrics](https://scikit-learn.org/stable/modules/cross_validation.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9EY53jyCqls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## YOUR CODE HERE\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "def cv(x, y, model):\n",
        "  print(cross_val_score(model, X, y, cv=5, scoring='roc_auc'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## END YOUR CODE"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPQdcsp2Cqlu",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Baseline model - logistic regression\n",
        "Our first algorithm will be logistic regression, since it's always nice to know how well can we do with a simple algorithm.\n",
        "* Should we use class_weight = 'balanced' in sklearn logistic regression? why?\n",
        "* Check how the results differ with and without the 'balanced' parameter - use `cv(x, y, model)` for that purpose, explain your answer\n",
        "* Fit a model on X_train, y_train and plot the precision recall curve on the test data.\n",
        "* If we would plot this curve on each fold (of the 5 folds in the cross validation), would we get exactly the same plot?\n",
        "\n",
        "Do not change other hyperparameters\n",
        "\n",
        "[precision recall curve](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWcmrdMbCqlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx0IU4EaCqlw",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tFF-GsLCqlx",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 ANN\n",
        "ANN (MLPClassifier in sklearn):\n",
        "\n",
        "* Fit a model on X_train, y_train and print the AUC and the Log Loss on the train and test data.\n",
        "* Explain your results - are they better or worse than the baseline? try to explain why\n",
        "\n",
        "Do not change hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kHOtZsqCqlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8WBLaBUCqlz",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHYMEb55Cqlz",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Random forest\n",
        "Random Forest classifier:\n",
        "\n",
        "* Fit a model on X_train, y_train and print the AUC and the Log Loss on the train and test data.\n",
        "* Explain your results - are they better or worse than the baseline? try to explain why\n",
        "\n",
        "Do not change hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPBPod-yCql0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2pTnSKtCql2",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwOwBPGHCql2",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 Confusion matrix\n",
        "Plot/print the confusion matrix of the random forest model on the test data\n",
        "\n",
        "Explain shortly your results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c_ImO_nCql3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_ihz7YhCql4",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-54VcMmCql5",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 Global feature importance of the random forest and SHAP\n",
        "\n",
        "* Plot the global feature importance of the features - use SHAP for this purpsose\n",
        "* Choose two samples from the dataset and plot/print the local explanations for this samples. Explain which features\n",
        "are important\n",
        "* Explain in few words how this feature importance is calculated\n",
        "\n",
        "**SHAP can be very slow on the random forest model. Thus, train another model with shallow trees (depth <7 for example) and you can also compute the SHAP values on a small data set. If it is yet very slow you, try to fit a different classifier for this purpose (MLP for example or GradientBoostingClassifier). You can also discard the binary features (which derived from the categorical features) for this purpose and stay only with the numerical ones.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_DmqsyoCql5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nThOjCCCql7",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWSZ3aJUCql7",
        "colab_type": "text"
      },
      "source": [
        "## 4 Clustering\n",
        "Imagine that we don't really know the true labels -> we need to use unsupervised machine learning.\n",
        "\n",
        "* Perform k means on X_train with k = 2. Is our clusters represent rich and poor people (does one cluster represent 'rich' ('>= 50k') people and the other 'poor' people)?\n",
        "\n",
        "* Do the same with dbscan, understand how many clusters did you get and the proportion of 'rich' and 'poor' people in each cluster.\n",
        "\n",
        "* Plot the clusters using pca (only for the kmeans). Are they seperated in the PCA dimension?\n",
        " \n",
        "This question is more open minded and you can (recomended) use graphs that explain how well did the clustering work. Did it work well?? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55RxSR4sCql8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cYh51FqCql-",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    }
  ]
}