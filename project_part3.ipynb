{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "project_part3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Galzi1/DataDiscoveryNNProj/blob/master/project_part3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIWWmCBEaLQY",
        "colab_type": "text"
      },
      "source": [
        "# Knowledge Data Discovery and Neural Networks : Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U7xi0ouaLQd",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we will encounter the domain of recommender systems.\n",
        "\n",
        "The purpose of this section is to be able to face a new problem with the the skills you have thus far.\n",
        "\n",
        "The grade will be based on your results on the test set and will be realtive to the other class mates - we attach a file \"example_submission.csv\" which you need to submit so we can check your results on the test set -\"recommender_test.csv\" (only we know the labels), you need to use \"recommender_train.csv\" for the training and validation of the algorithm you choose. We will test you on the root mean squared error metric (RMSE).\n",
        "\n",
        "We add here a couple of questions to guide you throw the process of understanding the problem world, but they will not be graded.\n",
        "We recommend to try and use a couple of algorithms from [surprise package](http://surpriselib.com/) and find the one that works best for you. \n",
        "\n",
        "We **recommend** to read a couple of posts online on \"collaborative filtering\" in recommender systems to get to know the topic.\n",
        "\n",
        "#### guided questions - \n",
        "\n",
        "1. What are the features we have? are they numerical or categorical or do we have both?\n",
        "2. What are we trying to predict, is it classification or regression?\n",
        "3. Offer a very simple prediction algorithm that you may use and can implement yourself (it doesn't have to be complicated but make sure at least that each user gets a differnt rating for an item in the test set) - you may find it useful especially if you will have problems with [surprise package](http://surpriselib.com/) or other package that you want to use.\n",
        "\n",
        "\n",
        "It is recommended to read the [original paper on svd](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf).\n",
        "Other resources on collaborative filtering:\n",
        "\n",
        "* [collaborative filtering with knn ](https://medium.com/sfu-cspmp/recommendation-systems-user-based-collaborative-filtering-using-n-nearest-neighbors-bf7361dc24e0)\n",
        "* [more collaborative filtering](https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-1-knn-item-based-collaborative-filtering-637969614ea)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KApFDK1oaLQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add more packages in this section\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import surprise # install it first\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag8xWJU1aLQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train = pd.read_csv(\"data/recommender_train.csv\")\n",
        "train = pd.read_csv(\"https://raw.githubusercontent.com/Galzi1/DataDiscoveryNNProj/master/data/recommender_train.csv\")\n",
        "# test = pd.read_csv(\"data/recommender_test.csv\")\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/Galzi1/DataDiscoveryNNProj/master/data/recommender_test.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uATA8TJ6uRgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "dd3d7250-24f6-4a2f-f07c-e74e94d75cdf"
      },
      "source": [
        "!pip install scikit-surprise"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/da/b5700d96495fb4f092be497f02492768a3d96a3f4fa2ae7dea46d4081cfa/scikit-surprise-1.1.0.tar.gz (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.12.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.0-cp36-cp36m-linux_x86_64.whl size=1670731 sha256=76ad07f9532dc1191ef5a4f47b228cb915300caacc6974cc7a11709f8b2bb59e\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/fa/8c/16c93fccce688ae1bde7d979ff102f7bee980d9cfeb8641bcf\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIJYeB0Ts-9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "74fba60e-3984-417a-9ae0-4914c6909f8c"
      },
      "source": [
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# A reader is still needed but only the rating_scale param is requiered.\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(train, reader)\n",
        "# data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# Use the famous SVD algorithm.\n",
        "algo = SVD()\n",
        "\n",
        "# Run 5-fold cross-validation and print results.\n",
        "cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.8776  0.8762  0.8789  0.8768  0.8757  0.8770  0.0011  \n",
            "Fit time          36.50   37.41   37.45   38.17   38.31   37.57   0.65    \n",
            "Test time         2.22    1.85    2.26    1.89    2.26    2.10    0.19    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (36.503912925720215,\n",
              "  37.40547561645508,\n",
              "  37.453688621520996,\n",
              "  38.17231583595276,\n",
              "  38.31275272369385),\n",
              " 'test_rmse': array([0.8775934 , 0.87619842, 0.87885303, 0.87682109, 0.87572039]),\n",
              " 'test_time': (2.2242040634155273,\n",
              "  1.8491623401641846,\n",
              "  2.2564122676849365,\n",
              "  1.8928565979003906,\n",
              "  2.2615203857421875)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXvWLH_1aLRA",
        "colab_type": "text"
      },
      "source": [
        "### Predictions\n",
        "\n",
        "For your convience, we add a code that creates \"example_submission.csv\".\n",
        "You need to replace \"algo\" with your best algorithm.\n",
        "If you choose a different method to predict or create the algorithm you may write different code - it is not obligatory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFMEbkaPaLRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions = []\n",
        "# for _, row in test.iterrows():\n",
        "#     predictions.append(algo.predict(row['user'], row['item']).est)\n",
        "# pd.Series(predictions).to_csv('example_submission.csv', index = None, header = None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}