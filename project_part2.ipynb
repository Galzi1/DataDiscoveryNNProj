{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "project_part2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Galzi1/DataDiscoveryNNProj/blob/master/project_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDzKT-jJCqlb",
        "colab_type": "text"
      },
      "source": [
        "# Knowledge Data Discovery and Neural Networks : Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RNH1oP_Cqlc",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we will prepare data and run several algorithms for classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT8nIf--Cqlc",
        "colab_type": "text"
      },
      "source": [
        "# 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POfS3zjTCqld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add more packages in this section\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dredJsfHCqlg",
        "colab_type": "text"
      },
      "source": [
        "# 2. data preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JKEhltnCqlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"data/adult.data\", header = None)\n",
        "cols = ['age', 'workclass', 'fnlwgt','education','education_num','marital_status','occupation','relationship','race','sex','capital_gain', 'capital_loss'\n",
        "    ,'hours_per_week','native_country','y']\n",
        "data.columns = cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARDQJAR7Cqlj",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Categorical feature handling\n",
        "* Name two machine learning algorithms that can deal with categorical features without special handling?\n",
        "\n",
        "special handling = one hot encoding exc.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suReLsHsCqlj",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "* Naive Bayes (explain some)\n",
        "* Some Tree-based algorithm (specify one and explain)\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0uySf-WCqlk",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 One hot encoding \n",
        "\n",
        "* Remove the y column from the data variable and save it to the variable y\n",
        "* Transform the categorical columns to one hot encoding\n",
        "\n",
        "You may find get_dummies function in pandas useful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMmmDqo-Cqlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bh315H_Cqlm",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Train test split\n",
        "\n",
        "* Convert the y column - replace <=50K with 0 and >50K with 1 \n",
        "* Split the dataset into train and test set (use 15% for the test set)\n",
        "\n",
        "at the end, make sure you have the following variables:\n",
        "\n",
        "* X\n",
        "* y\n",
        "* X_train\n",
        "* X_test\n",
        "* y_train\n",
        "* y_test\n",
        "\n",
        "You may find sklearn train_test_split useful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8x0S20LCqln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRA1aiKyCqlo",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Numeric feature normalization\n",
        "\n",
        "* Scale the numeric features to to have zero mean (z score normalization)\n",
        "\n",
        "- Don't scale the boolean features\n",
        "\n",
        "You may find sklearn StandardScaler useful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC62JGeECqlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoJomS7QCqlr",
        "colab_type": "text"
      },
      "source": [
        "# 3 Models\n",
        "\n",
        "Create a function `cv(x, y, model)` (cv stands for cross validation) that gets a model (sklearn classifier) and the data.  \n",
        "The function should fit the model using k fold cross validation with k = 5, and print the 'roc_auc' on each fold (which is the scoring parameter for the cross val_score function).\n",
        "\n",
        "\n",
        "[Computing cross-validated metrics](https://scikit-learn.org/stable/modules/cross_validation.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9EY53jyCqls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPQdcsp2Cqlu",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Baseline model - logistic regression\n",
        "Our first algorithm will be logistic regression, since it's always nice to know how well can we do with a simple algorithm.\n",
        "* Should we use class_weight = 'balanced' in sklearn logistic regression? why?\n",
        "* Check how the results differ with and without the 'balanced' parameter - use `cv(x, y, model)` for that purpose, explain your answer\n",
        "* Fit a model on X_train, y_train and plot the precision recall curve on the test data.\n",
        "* If we would plot this curve on each fold (of the 5 folds in the cross validation), would we get exactly the same plot?\n",
        "\n",
        "Do not change other hyperparameters\n",
        "\n",
        "[precision recall curve](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWcmrdMbCqlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx0IU4EaCqlw",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tFF-GsLCqlx",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 ANN\n",
        "ANN (MLPClassifier in sklearn):\n",
        "\n",
        "* Fit a model on X_train, y_train and print the AUC and the Log Loss on the train and test data.\n",
        "* Explain your results - are they better or worse than the baseline? try to explain why\n",
        "\n",
        "Do not change hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kHOtZsqCqlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8WBLaBUCqlz",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHYMEb55Cqlz",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Random forest\n",
        "Random Forest classifier:\n",
        "\n",
        "* Fit a model on X_train, y_train and print the AUC and the Log Loss on the train and test data.\n",
        "* Explain your results - are they better or worse than the baseline? try to explain why\n",
        "\n",
        "Do not change hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPBPod-yCql0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2pTnSKtCql2",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwOwBPGHCql2",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 Confusion matrix\n",
        "Plot/print the confusion matrix of the random forest model on the test data\n",
        "\n",
        "Explain shortly your results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c_ImO_nCql3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_ihz7YhCql4",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-54VcMmCql5",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 Global feature importance of the random forest and SHAP\n",
        "\n",
        "* Plot the global feature importance of the features - use SHAP for this purpsose\n",
        "* Choose two samples from the dataset and plot/print the local explanations for this samples. Explain which features\n",
        "are important\n",
        "* Explain in few words how this feature importance is calculated\n",
        "\n",
        "**SHAP can be very slow on the random forest model. Thus, train another model with shallow trees (depth <7 for example) and you can also compute the SHAP values on a small data set. If it is yet very slow you, try to fit a different classifier for this purpose (MLP for example or GradientBoostingClassifier). You can also discard the binary features (which derived from the categorical features) for this purpose and stay only with the numerical ones.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_DmqsyoCql5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nThOjCCCql7",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWSZ3aJUCql7",
        "colab_type": "text"
      },
      "source": [
        "## 4 Clustering\n",
        "Imagine that we don't really know the true labels -> we need to use unsupervised machine learning.\n",
        "\n",
        "* Perform k means on X_train with k = 2. Is our clusters represent rich and poor people (does one cluster represent 'rich' ('>= 50k') people and the other 'poor' people)?\n",
        "\n",
        "* Do the same with dbscan, understand how many clusters did you get and the proportion of 'rich' and 'poor' people in each cluster.\n",
        "\n",
        "* Plot the clusters using pca (only for the kmeans). Are they seperated in the PCA dimension?\n",
        " \n",
        "This question is more open minded and you can (recomended) use graphs that explain how well did the clustering work. Did it work well?? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55RxSR4sCql8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cYh51FqCql-",
        "colab_type": "text"
      },
      "source": [
        "#### YOUR VERBAL SOLUTION HERE\n",
        "\n",
        "\n",
        "\n",
        "#### END YOUR VERBAL SOLUTION HERE"
      ]
    }
  ]
}